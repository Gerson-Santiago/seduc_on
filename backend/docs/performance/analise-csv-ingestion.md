# An√°lise de Ingest√£o de CSV - SEDUC ON

**Data:** _A ser preenchido_  
**Sistema:** SEDUC ON - Integra√ß√£o com SED

---

## üìã Objetivo

Analisar o processo atual de importa√ß√£o de arquivos CSV da Secretaria de Educa√ß√£o (SED), identificar gargalos de performance e propor melhorias mantendo a arquitetura Node.js atual.

---

## 1. Processo Atual de Importa√ß√£o

### 1.1 Fluxo de Dados

```mermaid
graph LR
    A[CSV da SED] --> B[Download/Recebimento]
    B --> C[Node.js - csv-parser]
    C --> D[Processamento em mem√≥ria]
    D --> E[Prisma - Bulk Insert]
    E --> F[PostgreSQL - alunos_integracao_all]
    F --> G[Processamento para tabelas finais]
```

### 1.2 Scripts de Importa√ß√£o Existentes

**Localiza√ß√£o:** _A identificar no reposit√≥rio_

```bash
# Procurar por scripts de importa√ß√£o
find /home/sant/seduc_on -name "*csv*" -o -name "*import*"
```

**Scripts encontrados:**
- _A listar_

---

## 2. An√°lise de Performance Atual

### 2.1 Caracter√≠sticas do CSV

| M√©trica | Valor T√≠pico |
|---------|--------------|
| Tamanho do arquivo | _X MB_ |
| N√∫mero de linhas | _N alunos_ |
| N√∫mero de colunas | ~50 campos |
| Codifica√ß√£o | UTF-8 / ISO-8859-1 |
| Delimitador | `,` ou `;` |

### 2.2 Tempo de Processamento

**Medi√ß√£o:**
```bash
time node scripts/importar-csv.js caminho/para/ALUNOS.csv
```

| Etapa | Tempo (s) |
|-------|-----------|
| Leitura do arquivo | _TBD_ |
| Parsing CSV | _TBD_ |
| Transforma√ß√£o de dados | _TBD_ |
| Inser√ß√£o no banco | _TBD_ |
| **TOTAL** | _TBD_ |

### 2.3 Impacto no Banco de Dados

**Durante a importa√ß√£o, monitorar:**

```sql
-- Monitorar locks
SELECT * FROM pg_locks WHERE granted = false;

-- Monitorar conex√µes ativas
SELECT count(*) FROM pg_stat_activity;

-- Monitorar IO
SELECT * FROM pg_stat_database WHERE datname = 'seduc_on';
```

**Resultados observados:**
- Locks de tabela: _Sim/N√£o_
- CPU do PostgreSQL: _%_
- IO disk: _MB/s_
- Conex√µes bloqueadas: _N_

---

## 3. An√°lise do C√≥digo de Importa√ß√£o

### 3.1 Biblioteca Usada: csv-parser

```javascript
import csv from 'csv-parser';
import fs from 'fs';

// C√≥digo t√≠pico
fs.createReadStream('alunos.csv')
  .pipe(csv())
  .on('data', (row) => {
    // Processar linha por linha
  })
  .on('end', () => {
    console.log('CSV processado');
  });
```

**An√°lise:**
- ‚úÖ Streaming - n√£o carrega tudo em mem√≥ria
- ‚ö†Ô∏è Processamento linha por linha pode ser lento para inser√ß√£o

### 3.2 Estrat√©gia de Inser√ß√£o

**Cen√°rio 1: Inser√ß√£o linha por linha**
```javascript
for (const row of rows) {
  await prisma.alunos_integracao_all.create({ data: row });
}
```
- ‚ùå **Muito lento** - 1 query por linha

**Cen√°rio 2: Batch insert**
```javascript
await prisma.alunos_integracao_all.createMany({
  data: rows,
  skipDuplicates: true
});
```
- ‚úÖ **Mais eficiente** - 1 query para m√∫ltiplas linhas

**Cen√°rio Atual:** _A identificar_

---

## 4. Gargalos Identificados

### 4.1 Leitura do Arquivo

**Problema potencial:**
- Arquivo muito grande carregado inteiro na mem√≥ria

**Solu√ß√£o:**
- ‚úÖ Usar streaming (j√° usando `csv-parser`)

### 4.2 Parsing e Valida√ß√£o

**Problema potencial:**
- Convers√£o de tipos (datas, n√∫meros)
- Valida√ß√£o de dados

**Medi√ß√£o:**
```javascript
const start = Date.now();
const parsed = parseRow(row);
const duration = Date.now() - start;
```

**Tempo m√©dio por linha:** _X ms_

### 4.3 Inser√ß√£o no Banco

**Problema potencial:**
- Inser√ß√µes individuais vs batch
- Transa√ß√µes grandes travando o banco

**Teste de batch sizes:**

| Batch Size | Tempo Total (s) | Linhas/s |
|------------|-----------------|----------|
| 1 (individual) | _TBD_ | _TBD_ |
| 100 | _TBD_ | _TBD_ |
| 500 | _TBD_ | _TBD_ |
| 1000 | _TBD_ | _TBD_ |
| 5000 | _TBD_ | _TBD_ |

**Batch size √≥timo:** _N linhas_

### 4.4 Locks e Concorr√™ncia

**Problema potencial:**
- Importa√ß√£o trava a tabela
- Usu√°rios n√£o conseguem acessar sistema durante importa√ß√£o

**Teste:**
1. Iniciar importa√ß√£o
2. Tentar acessar `/api/alunos/stats`
3. Medir tempo de resposta

**Resultado:** _A preencher_

---

## 5. Propostas de Otimiza√ß√£o

### 5.1 Otimiza√ß√£o de Inser√ß√£o (Prioridade ALTA)

**Implementar batch insert com tamanho √≥timo:**

```javascript
import csv from 'csv-parser';
import fs from 'fs';

const BATCH_SIZE = 1000; // Ajustar conforme teste
let batch = [];

fs.createReadStream('alunos.csv')
  .pipe(csv())
  .on('data', async (row) => {
    batch.push(transformRow(row));
    
    if (batch.length >= BATCH_SIZE) {
      await prisma.alunos_integracao_all.createMany({
        data: batch,
        skipDuplicates: true
      });
      batch = [];
    }
  })
  .on('end', async () => {
    // Inserir √∫ltimos registros
    if (batch.length > 0) {
      await prisma.alunos_integracao_all.createMany({
        data: batch,
        skipDuplicates: true
      });
    }
  });
```

**Ganho esperado:** 50-80% redu√ß√£o de tempo

### 5.2 Processamento Ass√≠ncrono (Prioridade M√âDIA)

**Para CSVs muito grandes:**

```javascript
// Backend exp√µe rota para iniciar importa√ß√£o
app.post('/api/sed/importar-csv', async (req, res) => {
  // N√£o espera processar, responde imediatamente
  res.json({ status: 'processando', jobId: '123' });
  
  // Processar em background
  processCSVInBackground(req.file.path);
});

// Rota para verificar status
app.get('/api/sed/import-status/:jobId', (req, res) => {
  res.json({ 
    status: 'concluido' | 'processando' | 'erro',
    progress: '80%'
  });
});
```

**Vantagens:**
- Usu√°rio n√£o precisa esperar
- Sistema continua responsivo

**Desvantagens:**
- Mais complexidade
- Necessita gerenciamento de jobs

### 5.3 Uso de COPY (PostgreSQL Nativo)

**Para performance m√°xima:**

```javascript
// Usar COPY do PostgreSQL (muito mais r√°pido)
import { exec } from 'child_process';

exec(`psql -d seduc_on -c "\\COPY alunos_integracao_all FROM 'alunos.csv' CSV HEADER"`)
```

**Pr√≥s:**
- ‚ö° **Extremamente r√°pido** (10x mais r√°pido que inserts)

**Contras:**
- Bypassa ORM (Prisma)
- Menos controle sobre valida√ß√£o
- Requer acesso direto ao PostgreSQL

### 5.4 Paraleliza√ß√£o (Prioridade BAIXA)

**Para arquivos muito grandes:**

```javascript
// Dividir CSV em chunks e processar em paralelo
const chunks = splitCSV('alunos.csv', 10000); // 10k linhas por chunk
await Promise.all(chunks.map(chunk => processChunk(chunk)));
```

**Aten√ß√£o:** Pode sobrecarregar banco de dados

---

## 6. Valida√ß√£o de Dados

### Problemas Comuns em CSVs

- **Datas inv√°lidas:** `00/00/0000`
- **Campos vazios:** Tratar como `NULL`
- **Encoding:** ISO-8859-1 vs UTF-8
- **Delimitador:** `,` vs `;`

### Estrat√©gia de Tratamento

```javascript
function transformRow(row) {
  return {
    nome_aluno: row.nome_aluno || null,
    ra: row.ra,
    data_nasci: parseDate(row.data_nasci), // Validar e converter
    situacao: row.situacao?.toUpperCase(),
    // ... outros campos
  };
}

function parseDate(dateStr) {
  if (!dateStr || dateStr === '00/00/0000') return null;
  // Converter para formato ISO
  const [day, month, year] = dateStr.split('/');
  return new Date(`${year}-${month}-${day}`);
}
```

---

## 7. Monitoramento Durante Importa√ß√£o

### Script de Monitoramento

```javascript
let totalProcessed = 0;
let startTime = Date.now();

setInterval(() => {
  const elapsed = (Date.now() - startTime) / 1000;
  const rate = totalProcessed / elapsed;
  console.log(`Processadas: ${totalProcessed} | Taxa: ${rate.toFixed(0)} linhas/s`);
}, 5000); // Log a cada 5 segundos
```

---

## 8. Decis√£o e Recomenda√ß√µes

### Implementar Imediatamente

1. ‚úÖ **Batch insert** com tamanho √≥timo (1000-5000 linhas)
2. ‚úÖ **Valida√ß√£o e transforma√ß√£o** de dados
3. ‚úÖ **Logging de progresso**

### Implementar se Necess√°rio

4. ‚ö° **Processamento ass√≠ncrono** (se importa√ß√£o > 2 minutos)
5. ‚ö° **COPY nativo PostgreSQL** (se batch insert n√£o for suficiente)

### N√£o Recomendado no Momento

- ‚ùå Migra√ß√£o para Python para processamento CSV
- ‚ùå Paraleliza√ß√£o complexa
- ‚ùå Separa√ß√£o de servi√ßos

### Veredito

> [!NOTE]
> **Recomenda√ß√£o:** _A preencher ap√≥s testes_
>
> **Justificativa:**
> - _Baseado em tempo de importa√ß√£o medido_
> - _Adequado para equipe de 2 desenvolvedores_

---

## 9. Plano de Implementa√ß√£o

### Fase 1: Medi√ß√£o
- [ ] Medir tempo atual de importa√ß√£o
- [ ] Identificar gargalo principal

### Fase 2: Otimiza√ß√£o
- [ ] Implementar batch insert
- [ ] Testar diferentes tamanhos de batch
- [ ] Adicionar valida√ß√£o de dados

### Fase 3: Valida√ß√£o
- [ ] Re-medir tempo de importa√ß√£o
- [ ] Validar dados importados
- [ ] Documentar processo

---

## 10. Como Executar a An√°lise

```bash
# Localizar scripts de importa√ß√£o
find /home/sant/seduc_on -name "*csv*" -type f

# Executar importa√ß√£o com medi√ß√£o de tempo
time node caminho/para/script-import.js

# Monitorar PostgreSQL durante importa√ß√£o (outro terminal)
watch -n 2 'psql -U <user> -d seduc_on -c "SELECT count(*) FROM alunos_integracao_all"'
```

---

## Refer√™ncias

- [csv-parser documentation](https://www.npmjs.com/package/csv-parser)
- [Prisma - Batch Operations](https://www.prisma.io/docs/concepts/components/prisma-client/crud#create-multiple-records)
- [PostgreSQL COPY command](https://www.postgresql.org/docs/current/sql-copy.html)
